{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTS:   \n",
    "    def __init__(self, ts):\n",
    "             self.ts = ts\n",
    "            \n",
    "    def cov_mat(self, centering = True):\n",
    "        X = self.ts\n",
    "        if centering:\n",
    "            X = (self.ts - (self.ts).mean(axis = 0))\n",
    "        return (X.transpose() @ X)/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPCA:\n",
    "    def __init__(self, epsilon = 1e-5):\n",
    "        self.cov = None\n",
    "        self.epsilon = epsilon\n",
    "        self.U = None\n",
    "        self.V = None\n",
    "        self.S = None\n",
    "    \n",
    "    def fit(self,listMTS):\n",
    "        if (len(listMTS) > 0):\n",
    "            P = listMTS[0].cov_mat().shape[1]\n",
    "            cov_mat = [mat.cov_mat() for mat in listMTS]\n",
    "            self.cov = sum(cov_mat)/len(cov_mat)\n",
    "            #Add epsilon Id in order to ensure invertibility\n",
    "            cov = self.cov + self.epsilon*np.eye(P)\n",
    "            #Compute SVD\n",
    "            U,S,V = np.linalg.svd(self.cov)\n",
    "            #Save SVD\n",
    "            self.U = U\n",
    "            self.S = S\n",
    "            self.V = V\n",
    "        \n",
    "\n",
    "    def pred(self, listMTS, ncp):\n",
    "        predicted = []\n",
    "        if (self.U is not None):\n",
    "            predicted = [elem.ts @ self.U[:,:ncp] for elem in listMTS]\n",
    "        return predicted\n",
    "    \n",
    "    def reconstitution_error(self, listMTS, ncp):\n",
    "        mse = np.full(len(listMTS),np.inf)\n",
    "        if (self.U is not None):\n",
    "            prediction = self.pred(listMTS, ncp)\n",
    "            reconstit = [elem @ ((self.U)[:,:ncp].transpose()) for elem in prediction]\n",
    "            mse = [((listMTS[i].ts - reconstit[i])**2).sum() for i in range(len(prediction))]\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import lp1 for test\n",
    "import pandas as pd\n",
    "res = [pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/robotfailure-mld/lp1.data\", sep = \"\\t\",skiprows=1+(18*i), nrows=15, header = None) for i in range(1,80)]\n",
    "res = [MTS(elem.drop(columns = [0]).to_numpy()) for elem in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/robotfailure-mld/lp1.data\", sep = \"\\t\",skiprows=(18*i), nrows=1, header = None) for i in range(1,80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [elem[0][0] for elem in name]\n",
    "\n",
    "name_unique = list(np.unique(name))\n",
    "dict_name = dict(zip(name_unique, list(range(len(name_unique)))))\n",
    "\n",
    "gt_nb_cluster = np.array([dict_name.get(nom) for nom in name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Pre $=\\sum_{j=1}^{K} \\underbrace{\\frac{\\left|C_{j}\\right|}{N}}_{\\text{prop_part}} \\times \\underbrace{\\max _{i=1,2, \\cdots, g} \\frac{\\left|G_{i} \\cap C_{j}\\right|}{\\left|C_{j}\\right|}}_{\\text{max_part}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mc2PCA:\n",
    "    def __init__(self,K, ncp, itermax = 1000, conv_crit = 1e-5):\n",
    "        self.K = K\n",
    "        self.N = None\n",
    "        self.ncp = ncp\n",
    "        self.iter_max = itermax\n",
    "        self.converged = False\n",
    "        self.CPCA_final = None\n",
    "        self.conv_crit = conv_crit\n",
    "        self.pred = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        N = len(X)\n",
    "        #initialisation\n",
    "        index_cluster = np.tile(np.arange(self.K), int(N/self.K) + 1)[:N]\n",
    "        to_continue = True\n",
    "        i = 0\n",
    "        old_error = -1\n",
    "        \n",
    "        while to_continue:\n",
    "\n",
    "            #Split all MTS according to the cluster \n",
    "            #we store it in a list of lists of MTS (each list inside the list corresponding to a cluster)\n",
    "            MTS_by_cluster = [[X[i] for i in list(np.where(index_cluster == j)[0])] for j in range(self.K)]\n",
    "\n",
    "            CPCA_by_cluster = [CPCA() for i in range(self.K)]\n",
    "\n",
    "            #fit by cluster\n",
    "            [CPCA_by_cluster[i].fit(MTS_by_cluster[i]) for i in range(self.K)]\n",
    "\n",
    "            res = np.array([cpca.reconstitution_error(X, self.ncp) for cpca in CPCA_by_cluster])\n",
    "            #Update index cluster\n",
    "            index_cluster = res.argmin(axis = 0)\n",
    "\n",
    "            #new total error \n",
    "            new_error = res.min(axis = 0).sum()\n",
    "            to_continue = (abs(old_error - new_error) > self.conv_crit) & (self.iter_max > i)\n",
    "            self.converged = np.abs(old_error - new_error) < self.conv_crit\n",
    "\n",
    "            #Updata\n",
    "            old_error = new_error \n",
    "            i += 1\n",
    "        self.CPCA_final = CPCA_by_cluster\n",
    "        self.pred = index_cluster\n",
    "        return index_cluster\n",
    "    \n",
    "    def precision(self,gt_cluster):\n",
    "        index_cluster = self.pred\n",
    "        N = gt_cluster.shape[0]\n",
    "        g = np.unique(gt_cluster)\n",
    "        nb_g = g.shape[0]\n",
    "\n",
    "        G = [np.where(gt_cluster == i)[0] for i in range(nb_g)]\n",
    "        C = [np.where(index_cluster == i)[0] for i in range(self.K)]\n",
    "\n",
    "        max_part = np.array([max([np.intersect1d(G[i],C[j]).shape[0]/C[j].shape[0] for i in range(nb_g)]) for j in range(self.K)])\n",
    "        prop_part = np.array([C[j].shape[0]/N for j in range(self.K)])\n",
    "        return max_part.dot(prop_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 2, 1, 0,\n",
       "       3, 2, 3, 2, 3, 3, 2, 0, 2, 2, 1, 3, 3, 1, 2, 2, 2, 3, 0, 3, 2, 3,\n",
       "       3, 0, 1, 1, 2, 1, 2, 0, 0, 3, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 0, 0,\n",
       "       3, 3, 1, 1, 3, 0, 0, 3, 1, 2, 3, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Mc2PCA(4,1)\n",
    "m.fit(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44303797468354433"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.precision(gt_nb_cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat_app",
   "language": "python",
   "name": "stat_app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
