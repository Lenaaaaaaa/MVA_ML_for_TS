{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTS:   \n",
    "    def __init__(self, ts):\n",
    "             self.ts = ts\n",
    "            \n",
    "    def cov_mat(self, centering = True):\n",
    "        X = self.ts\n",
    "        if centering:\n",
    "            X = (self.ts - (self.ts).mean(axis = 0))\n",
    "        return X.transpose() @ X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPCA:\n",
    "    def __init__(self, epsilon = 1e-5):\n",
    "        self.cov = None\n",
    "        self.epsilon = epsilon\n",
    "        self.U = None\n",
    "        self.V = None\n",
    "        self.S = None\n",
    "    \n",
    "    def fit(self,listMTS):\n",
    "        if (len(listMTS) > 0):\n",
    "            P = listMTS[0].cov_mat().shape[1]\n",
    "            cov_mat = [mat.cov_mat() for mat in listMTS]\n",
    "            self.cov = sum(cov_mat)/len(cov_mat)\n",
    "            #Add epsilon Id in order to ensure invertibility\n",
    "            cov = self.cov + self.epsilon*np.eye(P)\n",
    "            #Compute SVD\n",
    "            U,S,V = np.linalg.svd(self.cov)\n",
    "            #Save SVD\n",
    "            self.U = U\n",
    "            self.S = S\n",
    "            self.V = V\n",
    "        \n",
    "\n",
    "    def pred(self, listMTS, ncp):\n",
    "        predicted = []\n",
    "        if (self.U is not None):\n",
    "            predicted = [elem.ts @ self.U[:,:ncp] for elem in listMTS]\n",
    "        return predicted\n",
    "    \n",
    "    def reconstitution_error(self, listMTS, ncp):\n",
    "        mse = np.full(len(listMTS),np.inf)\n",
    "        if (self.U is not None):\n",
    "            prediction = self.pred(listMTS, ncp)\n",
    "            reconstit = [elem @ ((self.U)[:,:ncp].transpose()) for elem in prediction]\n",
    "            mse = [((listMTS[i].ts - reconstit[i])**2).sum() for i in range(len(prediction))]\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import lp1 for test\n",
    "import pandas as pd\n",
    "res = [pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/robotfailure-mld/lp1.data\", sep = \"\\t\",skiprows=1+(18*i), nrows=15, header = None) for i in range(1,80)]\n",
    "res = [MTS(elem.drop(columns = [0]).to_numpy()) for elem in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/robotfailure-mld/lp1.data\", sep = \"\\t\",skiprows=(18*i), nrows=1, header = None) for i in range(1,80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [elem[0][0] for elem in name]\n",
    "\n",
    "name_unique = list(np.unique(name))\n",
    "dict_name = dict(zip(name_unique, list(range(len(name_unique)))))\n",
    "\n",
    "gt_nb_cluster = np.array([dict_name.get(nom) for nom in name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Pre $=\\sum_{j=1}^{K} \\underbrace{\\frac{\\left|C_{j}\\right|}{N}}_{\\text{prop_part}} \\times \\underbrace{\\max _{i=1,2, \\cdots, g} \\frac{\\left|G_{i} \\cap C_{j}\\right|}{\\left|C_{j}\\right|}}_{\\text{max_part}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mc2PCA:\n",
    "    def __init__(self,K, ncp, itermax = 1000, conv_crit = 1e-5):\n",
    "        self.K = K\n",
    "        self.N = None\n",
    "        self.ncp = ncp\n",
    "        self.iter_max = itermax\n",
    "        self.converged = False\n",
    "        self.CPCA_final = None\n",
    "        self.conv_crit = conv_crit\n",
    "        self.pred = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        N = len(X)\n",
    "        #initialisation\n",
    "        index_cluster = np.tile(np.arange(self.K), int(N/self.K) + 1)[:N]\n",
    "        to_continue = True\n",
    "        i = 0\n",
    "        old_error = -1\n",
    "        \n",
    "        while to_continue:\n",
    "\n",
    "            #Split all MTS according to the cluster \n",
    "            #we store it in a list of lists of MTS (each list inside the list corresponding to a cluster)\n",
    "            MTS_by_cluster = [[X[i] for i in list(np.where(index_cluster == j)[0])] for j in range(self.K)]\n",
    "\n",
    "            CPCA_by_cluster = [CPCA() for i in range(self.K)]\n",
    "\n",
    "            #fit by cluster\n",
    "            [CPCA_by_cluster[i].fit(MTS_by_cluster[i]) for i in range(self.K)]\n",
    "\n",
    "            res = np.array([cpca.reconstitution_error(X, self.ncp) for cpca in CPCA_by_cluster])\n",
    "            #Update index cluster\n",
    "            index_cluster = res.argmin(axis = 0)\n",
    "\n",
    "            #new total error \n",
    "            new_error = res.min(axis = 0).sum()\n",
    "            to_continue = (abs(old_error - new_error) > self.conv_crit) & (self.iter_max > i)\n",
    "            self.converged = np.abs(old_error - new_error) < self.conv_crit\n",
    "\n",
    "            #Updata\n",
    "            old_error = new_error \n",
    "            i += 1\n",
    "        self.CPCA_final = CPCA_by_cluster\n",
    "        self.pred = index_cluster\n",
    "        return index_cluster\n",
    "    \n",
    "    def precision(self,gt_cluster):\n",
    "        index_cluster = self.pred\n",
    "        N = gt_cluster.shape[0]\n",
    "        g = np.unique(gt_cluster)\n",
    "        nb_g = g.shape[0]\n",
    "\n",
    "        G = [np.where(gt_cluster == i)[0] for i in range(nb_g)]\n",
    "        C = [np.where(index_cluster == i)[0] for i in range(self.K)]\n",
    "        \n",
    "        #to handle case where a cluster is empty\n",
    "        max_part = list()\n",
    "        for j in range(self.K):\n",
    "            l = list()\n",
    "            for i in range(nb_g):\n",
    "                if len(C[j])!=0:\n",
    "                    l.append([np.intersect1d(G[i],C[j]).shape[0]/C[j].shape[0]])\n",
    "                else:\n",
    "                    l.append(0)\n",
    "            max_part.append(np.max(l))\n",
    "        max_part = np.array(max_part)\n",
    "        \n",
    "        #max_part = np.array([max([np.intersect1d(G[i],C[j]).shape[0]/C[j].shape[0] for i in range(nb_g)]) for j in range(self.K)])\n",
    "        prop_part = np.array([C[j].shape[0]/N for j in range(self.K)])\n",
    "        return max_part.dot(prop_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for best parameter ncp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_ncp(X,K,ncp_list,y_true):\n",
    "    pres = np.zeros(ncp_list.shape[0])\n",
    "    for i in range(len(ncp_list)):\n",
    "        m = Mc2PCA(K,ncp_list[i])\n",
    "        m.fit(X)\n",
    "        pres[i] = m.precision(y_true)\n",
    "    pre = np.max(pres)\n",
    "    best_ncp = ncp_list[np.argmax(pres)]\n",
    "    return best_ncp, pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on diabete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datasets/diabete/diabetes-data/'\n",
    "data_diabete = list()\n",
    "\n",
    "for i in range(70):\n",
    "    nb = str(i+1)\n",
    "    data_pd = pd.read_csv(path+'data-'+nb.zfill(2), sep='\\t', usecols = [1,2,3] , \n",
    "                       engine='python', header=None)\n",
    "    data_diabete.append(data_pd.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-e222474c6daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mMTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_diabete\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMc2PCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-33dca03f3b48>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#fit by cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mCPCA_by_cluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMTS_by_cluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstitution_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcpca\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCPCA_by_cluster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-33dca03f3b48>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#fit by cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mCPCA_by_cluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMTS_by_cluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstitution_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcpca\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCPCA_by_cluster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d6e2d614866c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, listMTS)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlistMTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistMTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistMTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mcov_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistMTS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0c91a47bebd9>\u001b[0m in \u001b[0;36mcov_mat\u001b[0;34m(self, centering)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcentering\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         ret = um.true_divide(\n\u001b[0m\u001b[1;32m    182\u001b[0m                 ret, rcount, out=ret, casting='unsafe', subok=False)\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_float16_result\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "res = [MTS(elem) for elem in data_diabete]\n",
    "m = Mc2PCA(3,2)\n",
    "m.fit(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on activities data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datasets/activity_recognition/realistic_sensor_displacement/'\n",
    "files = os.listdir(path)\n",
    "\n",
    "files_subset = files[:3]\n",
    "\n",
    "labels = list()\n",
    "data_activity = list()\n",
    "for f in files_subset:\n",
    "    if '.log' in f:\n",
    "        data_pd = pd.read_csv(path+f, sep='\\t', engine='python', header=None)\n",
    "        classes = data_pd[119]\n",
    "        i=0\n",
    "        while i < (len(classes)-1):\n",
    "            start = i\n",
    "            end = i\n",
    "            d = list()\n",
    "            labels.append(classes[i])\n",
    "            while classes[i]==classes[i+1]:\n",
    "                i += 1\n",
    "                end = i\n",
    "                if i==(len(classes)-1):\n",
    "                    d.append(data_pd.iloc[start:end].drop(columns=[0,119]).to_numpy())\n",
    "                    break\n",
    "            d.append(data_pd.iloc[start:end].drop(columns=[0,119]).to_numpy())\n",
    "            i +=1\n",
    "            data_activity.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "\n",
    "data_activities = list()\n",
    "for i in range(len(data_activity)):\n",
    "    data_activities.append(data_activity[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 13, 13, 13, 15, 13,\n",
       "       13, 11, 15, 13, 26, 11, 15, 13, 15, 26, 26, 13, 13, 13, 13, 13, 13,\n",
       "       13, 15, 13, 26, 11, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 11, 22, 11,  9, 13, 26, 13, 11, 11, 26, 26, 26,  3,  3,\n",
       "       11,  3, 11,  8,  8,  8,  8,  8,  8,  8, 12,  8, 14,  8,  8,  8,  8,\n",
       "        8,  8,  8, 12,  8,  8,  8, 12,  8, 12,  8, 12,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8, 12,  8, 12,  8,  8, 12, 12,  8, 12, 12, 12,  8, 12,\n",
       "        8, 12,  8, 12, 12, 12,  8, 27,  8,  8,  8,  8,  8,  8,  8,  8, 12,\n",
       "       12, 12])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [MTS(elem) for elem in data_activities]\n",
    "m = Mc2PCA(33,6)\n",
    "m.fit(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5434782608695652"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.precision(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 0.5217391304347826)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncp_list = np.arange(1,int(data_activities[0].shape[1]*3/4))\n",
    "search_ncp(res,3,ncp_list,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on gas sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>wine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   class\n",
       "0   0  banana\n",
       "1   1    wine\n",
       "2   2    wine\n",
       "3   3  banana\n",
       "4   4    wine"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'datasets/wine_banana/HT_Sensor_UCIsubmission/'\n",
    "\n",
    "metadata_pd = pd.read_csv(path+'HT_Sensor_metadata.dat', sep='\\t', usecols=[0,2],\n",
    "                          names=['id','class'], engine='python', skiprows=[0])\n",
    "metadata_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = metadata_pd['class']\n",
    "\n",
    "name_unique = list(np.unique(name))\n",
    "dict_name = dict(zip(name_unique, list(range(len(name_unique)))))\n",
    "\n",
    "labels = np.array([dict_name.get(nom) for nom in name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999750</td>\n",
       "      <td>12.8621</td>\n",
       "      <td>10.3683</td>\n",
       "      <td>10.4383</td>\n",
       "      <td>11.6699</td>\n",
       "      <td>13.4931</td>\n",
       "      <td>13.3423</td>\n",
       "      <td>8.04169</td>\n",
       "      <td>8.73901</td>\n",
       "      <td>26.2257</td>\n",
       "      <td>59.0528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>12.8617</td>\n",
       "      <td>10.3682</td>\n",
       "      <td>10.4375</td>\n",
       "      <td>11.6697</td>\n",
       "      <td>13.4927</td>\n",
       "      <td>13.3412</td>\n",
       "      <td>8.04133</td>\n",
       "      <td>8.73908</td>\n",
       "      <td>26.2308</td>\n",
       "      <td>59.0299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.999194</td>\n",
       "      <td>12.8607</td>\n",
       "      <td>10.3686</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>11.6696</td>\n",
       "      <td>13.4924</td>\n",
       "      <td>13.3405</td>\n",
       "      <td>8.04101</td>\n",
       "      <td>8.73915</td>\n",
       "      <td>26.2365</td>\n",
       "      <td>59.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.998916</td>\n",
       "      <td>12.8602</td>\n",
       "      <td>10.3686</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>11.6697</td>\n",
       "      <td>13.4921</td>\n",
       "      <td>13.3398</td>\n",
       "      <td>8.04086</td>\n",
       "      <td>8.73936</td>\n",
       "      <td>26.2416</td>\n",
       "      <td>58.9905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.998627</td>\n",
       "      <td>12.8595</td>\n",
       "      <td>10.3688</td>\n",
       "      <td>10.4374</td>\n",
       "      <td>11.6699</td>\n",
       "      <td>13.4919</td>\n",
       "      <td>13.3390</td>\n",
       "      <td>8.04087</td>\n",
       "      <td>8.73986</td>\n",
       "      <td>26.2462</td>\n",
       "      <td>58.9736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1        2        3        4        5        6        7   \\\n",
       "0   0 -0.999750  12.8621  10.3683  10.4383  11.6699  13.4931  13.3423   \n",
       "1   0 -0.999472  12.8617  10.3682  10.4375  11.6697  13.4927  13.3412   \n",
       "2   0 -0.999194  12.8607  10.3686  10.4370  11.6696  13.4924  13.3405   \n",
       "3   0 -0.998916  12.8602  10.3686  10.4370  11.6697  13.4921  13.3398   \n",
       "4   0 -0.998627  12.8595  10.3688  10.4374  11.6699  13.4919  13.3390   \n",
       "\n",
       "        8        9        10       11  \n",
       "0  8.04169  8.73901  26.2257  59.0528  \n",
       "1  8.04133  8.73908  26.2308  59.0299  \n",
       "2  8.04101  8.73915  26.2365  59.0093  \n",
       "3  8.04086  8.73936  26.2416  58.9905  \n",
       "4  8.04087  8.73986  26.2462  58.9736  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv(path+'HT_Sensor_dataset.dat', sep='  ', engine='python', skiprows=[0], header=None)\n",
    "\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = metadata_pd['id']\n",
    "data_gas = list()\n",
    "\n",
    "for i in range(ids.shape[0]):\n",
    "    data_id = data_pd[data_pd[0]==ids[i]]\n",
    "    data_id = data_id.drop(columns=[0])\n",
    "    data_id = data_id[data_id[1] >= 0]\n",
    "    data_gas.append(data_id.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-0c91a47bebd9>:8: RuntimeWarning: Mean of empty slice.\n",
      "  X = (self.ts - (self.ts).mean(axis = 0))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [MTS(elem) for elem in data_gas]\n",
    "m = Mc2PCA(3,1)\n",
    "m.fit(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.precision(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 0.47)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncp_list = np.arange(1,int(data_gas[0].shape[1]*3/4))\n",
    "search_ncp(res,3,ncp_list,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on sign language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datasets/sign_language/tctodd/'\n",
    "\n",
    "#list of lists, of all files per directory\n",
    "directories = os.listdir(path)\n",
    "directories = np.sort(directories)\n",
    "files = list()\n",
    "for direc in directories:\n",
    "    f=os.listdir(path+direc)\n",
    "    f = np.sort(f)\n",
    "    f = [path+direc+'/'+name for name in f]\n",
    "    files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_signs = 95\n",
    "sample_per_sign_per_file = 3\n",
    "signs = list()\n",
    "\n",
    "#create list of lists, of samples per signs (95 signs, and 27 samples per sign)\n",
    "for i in range(nb_signs):\n",
    "    sample_per_sign = list()\n",
    "    for l in range(len(files)):\n",
    "        for j in range(sample_per_sign_per_file):\n",
    "            sample_per_sign.append(files[l][i*3+j])\n",
    "    signs.append(sample_per_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_signs = list()\n",
    "\n",
    "for i in range(len(signs)):\n",
    "    for j in range(27):\n",
    "        sign = pd.read_csv(signs[i][j], sep='\\t', engine='python', header=None)\n",
    "        data_signs.append(sign.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "signs_names = list()\n",
    "\n",
    "for i in range(nb_signs):\n",
    "    for k in range(27):\n",
    "        signs_names.append(signs[i][0].split('/')[-1][:-6])\n",
    "        \n",
    "unique_names = np.unique(signs_names)\n",
    "\n",
    "dict_name = dict(zip(unique_names, list(range(len(unique_names)))))\n",
    "\n",
    "labels = np.array([dict_name.get(nom) for nom in signs_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 28, 28, ..., 62, 47, 47])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [MTS(elem) for elem in data_signs]\n",
    "m = Mc2PCA(95,6)\n",
    "m.fit(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08927875243664718"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.precision(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trop long\n",
    "\n",
    "ncp_list = np.arange(1,int(data_signs[0].shape[1]*3/4))\n",
    "#search_ncp(res,95,ncp_list,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on pioneer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datasets/pioneers/'\n",
    "\n",
    "data_pd = pd.read_csv(path+'MOVE.DATA', sep=',', engine='python', header=None)\n",
    "exp_names = np.unique(data_pd[0])\n",
    "\n",
    "data_pioneers0 = list()\n",
    "for i in range(exp_names.shape[0]):\n",
    "    exp_n = data_pd[data_pd[0]==exp_names[i]]\n",
    "    exp_n = exp_n.drop(columns=[0,1,2])\n",
    "    data_pioneers0.append(exp_n.to_numpy())\n",
    "\n",
    "#label 0: MOVE experience\n",
    "labels_MOVE = np.zeros(len(data_pioneers0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv(path+'GRIPPER.DATA', sep=',', engine='python', header=None)\n",
    "exp_names = np.unique(data_pd[0])\n",
    "\n",
    "data_pioneers1 = list()\n",
    "for i in range(exp_names.shape[0]):\n",
    "    exp_n = data_pd[data_pd[0]==exp_names[i]]\n",
    "    exp_n = exp_n.drop(columns=[0,1,2])\n",
    "    data_pioneers1.append(exp_n.to_numpy())\n",
    "\n",
    "#label 1: GRIPPER experience\n",
    "labels_GRIP = np.ones(len(data_pioneers1))\n",
    "labels = np.concatenate((labels_MOVE,labels_GRIP))\n",
    "data_pioneers = data_pioneers0 + data_pioneers1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv(path+'TURN.DATA', sep=',', engine='python', header=None)\n",
    "exp_names = np.unique(data_pd[0])\n",
    "\n",
    "data_pioneers2 = list()\n",
    "for i in range(exp_names.shape[0]):\n",
    "    exp_n = data_pd[data_pd[0]==exp_names[i]]\n",
    "    exp_n = exp_n.drop(columns=[0,1,2])\n",
    "    data_pioneers2.append(exp_n.to_numpy())\n",
    "\n",
    "#label 2: TURN experience\n",
    "labels_TURN = np.ones(len(data_pioneers2))*2\n",
    "#final list of labels\n",
    "labels = np.concatenate((labels,labels_TURN))\n",
    "#final list of data\n",
    "data_pioneers = data_pioneers + data_pioneers2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 2, 2, 1, 0, 1,\n",
       "       0, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1,\n",
       "       1, 1, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [MTS(elem) for elem in data_pioneers]\n",
    "m = Mc2PCA(3,6)\n",
    "m.fit(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6375"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.precision(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 0.675)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncp_list = np.arange(1,int(data_pioneers[0].shape[1]*3/4))\n",
    "search_ncp(res,3,ncp_list,labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
